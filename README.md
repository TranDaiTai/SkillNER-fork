<p align="center"><img width="50%" src="https://user-images.githubusercontent.com/56308112/128958594-79813e72-b688-4a9a-9267-324f098d4b0c.png" /></p>

[**Live demo**](https://share.streamlit.io/anasaito/skillner_demo/index.py) | [**Documentation**](https://badr-moufad.github.io/SkillNER/get_started.html) | [**Website**](https://skillner.vercel.app/)

----------------------


[![Downloads](https://static.pepy.tech/personalized-badge/skillner?period=month&units=international_system&left_color=blue&right_color=green&left_text=Downloads%20/%20months)](https://pepy.tech/project/skillner)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Just looking to test out SkillNer? Check out our [demo](https://anasaito-skillner-demo-index-4fiwi3.streamlit.app/)**.

SkillNer is an NLP module to automatically Extract skills and certifications from unstructured job postings, texts, and applicant's resumes.

Skillner uses [EMSI](https://skills.emsidata.com/) databse (an open source skill database) as a knowldge base linker to prevent skill duplications.



<p align="center"><img width="50%" src="https://user-images.githubusercontent.com/56308112/138768792-a25d25e7-1e43-4a44-aa46-8de9895ffe88.png" /></p>


## Installation

It is easy to get started with **SkillNer** and take advantage of its features.

1. First, install **SkillNer** through the ``pip``

```bash
pip install skillNer
```

2. Next, run the following command to install ``spacy en_core_web_lg ``
which is one of the main plugins of SkillNer. Thanks to its modular nature, you can 
customize SkillNer behavior just by adjusting  | plugin | unplugin modules. Don't worry about these details, we will discuss them in detail in the **upcoming Tutorial section**.

```bash
python -m spacy download en_core_web_lg
```

**Note:** The later installation will take a few seconds before it gets done since ``spacy en_core_web_lg `` is a bit too large (800 MB). Yet, you need to wait only one time.


## Example of usage

With these initial steps being accomplished, letâ€™s dive a bit deeper into skillNer through a worked example.

Letâ€™s say you want to extract skills from the following job posting:

    â€œYou are a Python developer with a solid experience in web development and can manage projects. 
    You quickly adapt to new environments and speak fluently English and Frenchâ€

### Annotating skills

We start first by importing modules, particularly spacy and SkillExtractor. Note that if you are using skillNer for the first time, it might take a while to download SKILL_DB.

**SKILL_DB** is SkillNer default skills database. It was built upon [EMSI skills database ](https://skills.emsidata.com/).



```python
# imports
import spacy
from spacy.matcher import PhraseMatcher

# load default skills data base
from skillNer.general_params import SKILL_DB
# import skill extractor
from skillNer.skill_extractor_class import SkillExtractor

# init params of skill extractor
nlp = spacy.load("en_core_web_lg")
# init skill extractor
skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)

# extract skills from job_description
job_description = """
You are a Python developer with a solid experience in web development
and can manage projects. You quickly adapt to new environments
and speak fluently English and French
"""

annotations = skill_extractor.annotate(job_description)

```



### Exploit annotations

VoilÃ ! Now you can inspect results by rendering the text with the annotated skills.
You can achieve that through the ``.describe`` method. Note that the output of this method is 
literally an HTML document that gets rendered in your notebook.


<p align="center">
    <img src="./screenshots/output-describe.gif" alt="example output skillNer"/>
</p>


Besides, you can use the raw result of the annotations. 
Below is the value of the ``annotations`` variable from the code above.


```python
# output
{
    'text': 'you are a python developer with a solid experience in web development and can manage projects you quickly adapt to new environments and speak fluently english and french',
    'results': {
        'full_matches': [
            {
                'skill_id': 'KS122Z36QK3N5097B5JH', 
                'doc_node_value': 'web development', 
                'score': 1, 'doc_node_id': [10, 11]
            }
        ], '
        ngram_scored': [
            {
                'skill_id': 'KS125LS6N7WP4S6SFTCK', 
                'doc_node_id': [3], 
                'doc_node_value': 'python', 
                'type': 'fullUni', 
                'score': 1, 
                'len': 1
            }, 
        # the other annotated skills
        # ...
        ]
    }
}
```

# Contribute

SkillNer is the first **Open Source** skill extractor. 
Hence it is a tool dedicated to the community and thereby relies on its contribution to evolve.

We did our best to adapt SkillNer for usage and fixed many of its bugs. Therefore, we believe its key features 
make it ready for a diversity of use cases. However, it still has not reached 100% stability. SkillNer needs the assistance of the community to be adapted further
and broaden its usage. 


You can contribute to SkillNer either by

1. Reporting issues. Indeed, you may encounter one while you are using SkillNer. So do not hesitate to mention them in the [issue section of our GitHub repository](https://github.com/AnasAito/SkillNER/issues). Also, you can use the issue as a way to suggest new features to be added.

2. Pushing code to our repository through pull requests. In case you fixed an issue or wanted to extend SkillNer features.


3. A third (friendly and not technical) option to contribute to SkillNer will be soon released. *So, stay tuned...*



Finally, make sure to read carefully [our guidelines](https://badr-moufad.github.io/SkillNER/contribute.html) before contributing. It will specify standards to follow so that we can understand what you want to say.


Besides, it will help you setup SkillNer on your local machine, in case you are willing to push code.


## Useful links

- [Visit our website](https://skillner.vercel.app/) to learn about SkillNer features, how it works, and particularly explore our roadmap
- Get started with SkillNer and get to know its API by visiting the [Documentation](https://badr-moufad.github.io/SkillNER/get_started.html)
- [Test our Demo](https://share.streamlit.io/anasaito/skillner_demo/index.py) to see some of SkillNer capabilities



## Fuzzy Matching (Typo-Tolerant Extraction)

Trong phiÃªn báº£n má»Ÿ rá»™ng nÃ y, SkillNer bá»• sung mÃ´-Ä‘un `FuzzyPhraseMatcher` nháº±m xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p sai chÃ­nh táº£, thiáº¿u/k dÆ° kÃ½ tá»±, hoáº·c cÃ¡ch viáº¿t khÃ´ng chuáº©n thÆ°á»ng gáº·p trong CV vÃ  JD.

### Váº¥n Ä‘á»

CÃ¡c matcher hiá»‡n cÃ³ (`full`, `abv`, `low`, `token`, `uni`) hoáº¡t Ä‘á»™ng ráº¥t tá»‘t khi dá»¯ liá»‡u Ä‘Ãºng chÃ­nh táº£. Tuy nhiÃªn, chÃºng dá»… bá» sÃ³t cÃ¡c cá»¥m nhiá»u token (multi-token phrases) khi xuáº¥t hiá»‡n typo, vÃ­ dá»¥:

- `pithon developer`
- `ful stack`
- `. net ful stack developer`

### Má»¥c tiÃªu

- PhÃ¡t hiá»‡n cá»¥m skill / job title Ä‘a token cÃ³ lá»—i chÃ­nh táº£ nháº¹.
- Chá»‰ sá»­a typo (nonâ€‘semantic), khÃ´ng má»Ÿ rá»™ng nghÄ©a.
- KhÃ´ng lÃ m giÃ¡n Ä‘oáº¡n hoáº·c phÃ¡ vá»¡ pipeline matcher hiá»‡n táº¡i.

### NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng

`FuzzyPhraseMatcher` hoáº¡t Ä‘á»™ng á»Ÿ phrase-level vá»›i cÃ¡c nguyÃªn táº¯c sau:

- So sÃ¡nh span token trong vÄƒn báº£n vá»›i full surface form trong surface DB.
- Chá»‰ Ã¡p dá»¥ng cho multi-token entries (token_len >= 2) Ä‘á»ƒ trÃ¡nh false positive.
- Sá»­ dá»¥ng Jaroâ€“Winkler similarity Ä‘á»ƒ Ä‘o Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a span vÃ  surface form.
- Ãp dá»¥ng thÃªm token-level gate nháº±m Ä‘áº£m báº£o má»—i token trong span Ä‘á»§ giá»‘ng token tÆ°Æ¡ng á»©ng trong skill/job gá»‘c.

### HÃ nh vi khi fuzzy match thÃ nh cÃ´ng

Khi má»™t fuzzy match há»£p lá»‡ Ä‘Æ°á»£c phÃ¡t hiá»‡n:

- ToÃ n bá»™ token trong span Ä‘Æ°á»£c gÃ¡n `token.is_matchable = False` Ä‘á»ƒ ngÄƒn cÃ¡c matcher yáº¿u hÆ¡n (low, token, uni) khá»›p láº¡i vÃ  â€œÄƒn máº¥tâ€ cá»¥m Ä‘Ã£ match.
- Tráº£ vá» annotation cÃ³ cáº¥u trÃºc tÆ°Æ¡ng tá»± `full_match`:

```
{
    "skill_id": "<skill_id>",
    "doc_node_value": "<span text>",
    "doc_node_id": [<token indices>],
    "type": "fuzzy",
    "score": <jaro_winkler_similarity>
}
```

Trong Ä‘Ã³ `score` biá»ƒu thá»‹ má»©c Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng fuzzy giá»¯a span vÃ  surface form gá»‘c.

### Lá»£i Ã­ch

- Báº¯t Ä‘Æ°á»£c skill / job title cÃ³ typo hoáº·c cÃ¡ch viáº¿t khÃ´ng chuáº©n trong CV/JD.
- Giáº£m Ä‘Ã¡ng ká»ƒ false negative á»Ÿ cáº¥p phrase.
- Giá»¯ nguyÃªn thá»© tá»± matcher hiá»‡n táº¡i vÃ  trÃ¡nh xung Ä‘á»™t span báº±ng cÆ¡ cháº¿ khoÃ¡ token (`is_matchable`).
- KhÃ´ng áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c matcher chÃ­nh xÃ¡c cao nhÆ° `full` hoáº·c `abv`.

### Gá»£i Ã½ triá»ƒn khai trong pipeline

- ThÃªm `FuzzyPhraseMatcher` nhÆ° má»™t bÆ°á»›c bá»• sung.
- Thá»© tá»± khuyáº¿n nghá»‹: `full` â†’ `abv` â†’ `fuzzy` â†’ `low` â†’ `token` â†’ `uni`.
- Cho phÃ©p cáº¥u hÃ¬nh ngÆ°á»¡ng Jaroâ€“Winkler (vÃ­ dá»¥: `0.88`â€“`0.92`) tuá»³ domain.
- Chá»‰ Ã¡p dá»¥ng fuzzy cho surface forms cÃ³ token length â‰¥ 2.



## ğŸ”„ Pipeline Xá»­ LÃ½ Skills (PhiÃªn Báº£n Má»›i)

Pipeline má»›i Ä‘Æ°á»£c thiáº¿t káº¿ láº¡i theo hÆ°á»›ng end-to-end, rÃµ rÃ ng vÃ  dá»… báº£o trÃ¬, cho phÃ©p cháº¡y toÃ n bá»™ hoáº·c tá»«ng bÆ°á»›c riÃªng láº», Ä‘á»“ng thá»i há»— trá»£ cáº¥u hÃ¬nh endpoint EMSI linh hoáº¡t.

Tá»•ng quan luá»“ng xá»­ lÃ½

EMSI API
     â†“
`raw_skillss.json`
     â†“
`skills_processed.json`
     â†“
`token_dist_skill.json`
     â†“
`skill_db_relax_20.json`

Pipeline nÃ y Ä‘Æ°á»£c Ä‘iá»u phá»‘i táº­p trung bá»Ÿi class `PipelineRunner`.

ğŸ§© Cáº¥u trÃºc pipeline & cÃ¡c module chÃ­nh

1ï¸âƒ£ `pipeline_runner.py` â€“ Orchestrator

Vai trÃ²:

 - Cháº¡y toÃ n bá»™ pipeline theo thá»© tá»± chuáº©n: Fetch raw skills tá»« Emsi API â†’ Process raw â†’ Táº¡o token distribution â†’ Sinh relax skill DB.

Æ¯u Ä‘iá»ƒm chÃ­nh:

 - CÃ³ thá»ƒ `force_fetch` hoáº·c tÃ¡i sá»­ dá»¥ng raw cÅ©.
 - In log theo tá»«ng bÆ°á»›c Ä‘á»ƒ dá»… debug.
 - Cho phÃ©p cáº¥u hÃ¬nh: `auth_endpoint`, `skills_endpoint`, Ä‘Æ°á»ng dáº«n output.

Sá»­ dá»¥ng:

```python
from pipeline_runner import PipelineRunner

runner = PipelineRunner(
        client_id="YOUR_ID",
        client_secret="YOUR_SECRET"
)

runner.run(force_fetch=False)
```

2ï¸âƒ£ `fetch_raw_data.py` â€“ Fetch dá»¯ liá»‡u tá»« Emsi API

`EmsiSkillsFetcher`

Chá»©c nÄƒng:

 - Láº¥y access token tá»« Emsi.
 - Fetch toÃ n bá»™ danh sÃ¡ch skills (Lightcast / EMSI).
 - Cache token Ä‘á»ƒ trÃ¡nh gá»i láº¡i nhiá»u láº§n.
 - LÆ°u raw data ra JSON (`data/raw_skillss.json`).

Äáº·c Ä‘iá»ƒm ká»¹ thuáº­t:

 - Timeout & error handling rÃµ rÃ ng.
 - Validate response (kiá»ƒm tra key `data`).
 - Endpoint cÃ³ thá»ƒ cáº¥u hÃ¬nh mÃ  khÃ´ng sá»­a code pipeline.

3ï¸âƒ£ `processed.py` â€“ Chuáº©n hoÃ¡ skill theo chuáº©n SkillNER

`SkillsProcessor`

Chá»©c nÄƒng:

 - LÃ m sáº¡ch tÃªn skill (Cleaner chuáº©n SkillNER).
 - Loáº¡i bá» mÃ´ táº£ trong ngoáº·c.
 - Lemmatize (spaCy) vÃ  stem (PorterStemmer).
 - TrÃ­ch xuáº¥t abbreviation (AWS, SQL, NLPâ€¦).

Output: `data/skills_processed.json`

Má»—i skill bao gá»“m:

```json
{
    "skill_name": "...",
    "skill_type": "...",
    "skill_cleaned": "...",
    "skill_len": 2,
    "skill_lemmed": "...",
    "skill_stemmed": "...",
    "match_on_stemmed": false,
    "abbreviation": "AWS"
}
```

ğŸ‘‰ Äá»‹nh dáº¡ng tÆ°Æ¡ng thÃ­ch trá»±c tiáº¿p vá»›i SkillNER gá»‘c.

4ï¸âƒ£ `create_token_dist.py` â€“ Token Distribution

`TokenDistGenerator`

Chá»©c nÄƒng:

 - TÃ­nh táº§n suáº¥t token.
 - Chá»‰ dÃ¹ng n-gram (skill_len > 1) Ä‘á»ƒ trÃ¡nh nhiá»…u.
 - Phá»¥c vá»¥ cho logic relax DB (unique token, rare token).

Output: `data/token_dist_skill.json`

VÃ­ dá»¥:

```json
{
    "data": 2134,
    "learning": 1876,
    "cloud": 912
}
```

5ï¸âƒ£ `create_surf_db.py` â€“ Sinh Relax Skill DB

`SkillRelaxDBGenerator`

Chá»©c nÄƒng chÃ­nh:

 - Sinh high surface forms: full, abbreviation.
 - Sinh low surface forms: stemmed, Ä‘áº£o token (bigram), token hiáº¿m, abbreviation regex.

Logic theo Ä‘á»™ dÃ i skill:

 - Skill length 1: match full + stem
 - Skill length 2: full (lemma) + stem + Ä‘áº£o token
 - Skill length >2: full (lemma) + match_on_tokens

Output cuá»‘i cÃ¹ng: `data/skill_db_relax_20.json`

ğŸ‘‰ ÄÃ¢y lÃ  file Ä‘Æ°á»£c dÃ¹ng trá»±c tiáº¿p bá»Ÿi `SkillExtractor`.

â–¶ï¸ Cháº¡y pipeline

Cháº¡y toÃ n bá»™ pipeline:

```python
runner = PipelineRunner()
runner.run()
```

LuÃ´n fetch raw má»›i tá»« API:

```python
runner.run(force_fetch=True)
```

ğŸ“¦ Output sau khi pipeline hoÃ n táº¥t
```
data/
 â”œâ”€ raw_skillss.json
 â”œâ”€ skills_processed.json
 â”œâ”€ token_dist_skill.json
 â””â”€ skill_db_relax_20.json
```

Báº¡n cÃ³ thá»ƒ dÃ¹ng trá»±c tiáº¿p `skill_db_relax_20.json` trong:

`SkillExtractor(nlp, SKILL_DB, PhraseMatcher)`

