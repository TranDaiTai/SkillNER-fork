<p align="center"><img width="50%" src="https://user-images.githubusercontent.com/56308112/128958594-79813e72-b688-4a9a-9267-324f098d4b0c.png" /></p>

[**Live demo**](https://share.streamlit.io/anasaito/skillner_demo/index.py) | [**Documentation**](https://badr-moufad.github.io/SkillNER/get_started.html) | [**Website**](https://skillner.vercel.app/)

----------------------


[![Downloads](https://static.pepy.tech/personalized-badge/skillner?period=month&units=international_system&left_color=blue&right_color=green&left_text=Downloads%20/%20months)](https://pepy.tech/project/skillner)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Just looking to test out SkillNer? Check out our [demo](https://anasaito-skillner-demo-index-4fiwi3.streamlit.app/)**.

SkillNer is an NLP module to automatically Extract skills and certifications from unstructured job postings, texts, and applicant's resumes.

Skillner uses [EMSI](https://skills.emsidata.com/) databse (an open source skill database) as a knowldge base linker to prevent skill duplications.



<p align="center"><img width="50%" src="https://user-images.githubusercontent.com/56308112/138768792-a25d25e7-1e43-4a44-aa46-8de9895ffe88.png" /></p>


## Installation

It is easy to get started with **SkillNer** and take advantage of its features.

1. First, install **SkillNer** through the ``pip``

```bash
pip install skillNer
```

2. Next, run the following command to install ``spacy en_core_web_lg ``
which is one of the main plugins of SkillNer. Thanks to its modular nature, you can 
customize SkillNer behavior just by adjusting  | plugin | unplugin modules. Don't worry about these details, we will discuss them in detail in the **upcoming Tutorial section**.

```bash
python -m spacy download en_core_web_lg
```

**Note:** The later installation will take a few seconds before it gets done since ``spacy en_core_web_lg `` is a bit too large (800 MB). Yet, you need to wait only one time.


## Example of usage

With these initial steps being accomplished, let‚Äôs dive a bit deeper into skillNer through a worked example.

Let‚Äôs say you want to extract skills from the following job posting:

    ‚ÄúYou are a Python developer with a solid experience in web development and can manage projects. 
    You quickly adapt to new environments and speak fluently English and French‚Äù

### Annotating skills

We start first by importing modules, particularly spacy and SkillExtractor. Note that if you are using skillNer for the first time, it might take a while to download SKILL_DB.

**SKILL_DB** is SkillNer default skills database. It was built upon [EMSI skills database ](https://skills.emsidata.com/).



```python
# imports
import spacy
from spacy.matcher import PhraseMatcher

# load default skills data base
from skillNer.general_params import SKILL_DB
# import skill extractor
from skillNer.skill_extractor_class import SkillExtractor

# init params of skill extractor
nlp = spacy.load("en_core_web_lg")
# init skill extractor
skill_extractor = SkillExtractor(nlp, SKILL_DB, PhraseMatcher)

# extract skills from job_description
job_description = """
You are a Python developer with a solid experience in web development
and can manage projects. You quickly adapt to new environments
and speak fluently English and French
"""

annotations = skill_extractor.annotate(job_description)

```



### Exploit annotations

Voil√†! Now you can inspect results by rendering the text with the annotated skills.
You can achieve that through the ``.describe`` method. Note that the output of this method is 
literally an HTML document that gets rendered in your notebook.


<p align="center">
    <img src="./screenshots/output-describe.gif" alt="example output skillNer"/>
</p>


Besides, you can use the raw result of the annotations. 
Below is the value of the ``annotations`` variable from the code above.


```python
# output
{
    'text': 'you are a python developer with a solid experience in web development and can manage projects you quickly adapt to new environments and speak fluently english and french',
    'results': {
        'full_matches': [
            {
                'skill_id': 'KS122Z36QK3N5097B5JH', 
                'doc_node_value': 'web development', 
                'score': 1, 'doc_node_id': [10, 11]
            }
        ], '
        ngram_scored': [
            {
                'skill_id': 'KS125LS6N7WP4S6SFTCK', 
                'doc_node_id': [3], 
                'doc_node_value': 'python', 
                'type': 'fullUni', 
                'score': 1, 
                'len': 1
            }, 
        # the other annotated skills
        # ...
        ]
    }
}
```

# Contribute

SkillNer is the first **Open Source** skill extractor. 
Hence it is a tool dedicated to the community and thereby relies on its contribution to evolve.

We did our best to adapt SkillNer for usage and fixed many of its bugs. Therefore, we believe its key features 
make it ready for a diversity of use cases. However, it still has not reached 100% stability. SkillNer needs the assistance of the community to be adapted further
and broaden its usage. 


You can contribute to SkillNer either by

1. Reporting issues. Indeed, you may encounter one while you are using SkillNer. So do not hesitate to mention them in the [issue section of our GitHub repository](https://github.com/AnasAito/SkillNER/issues). Also, you can use the issue as a way to suggest new features to be added.

2. Pushing code to our repository through pull requests. In case you fixed an issue or wanted to extend SkillNer features.


3. A third (friendly and not technical) option to contribute to SkillNer will be soon released. *So, stay tuned...*



Finally, make sure to read carefully [our guidelines](https://badr-moufad.github.io/SkillNER/contribute.html) before contributing. It will specify standards to follow so that we can understand what you want to say.


Besides, it will help you setup SkillNer on your local machine, in case you are willing to push code.


## Useful links

- [Visit our website](https://skillner.vercel.app/) to learn about SkillNer features, how it works, and particularly explore our roadmap
- Get started with SkillNer and get to know its API by visiting the [Documentation](https://badr-moufad.github.io/SkillNER/get_started.html)
- [Test our Demo](https://share.streamlit.io/anasaito/skillner_demo/index.py) to see some of SkillNer capabilities



## Fuzzy Matching (Typo-tolerant Extraction)

Trong phi√™n b·∫£n m·ªü r·ªông n√†y, SkillNer ƒë√£ b·ªï sung `FuzzyPhraseMatcher` nh·∫±m x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p nh·∫≠p sai, thi·∫øu/k d∆∞ k√Ω t·ª±, ho·∫∑c vi·∫øt kh√¥ng chu·∫©n trong CV/JD.

- V·∫•n ƒë·ªÅ: matcher hi·ªán c√≥ (`full`, `low`, `token`, `uni`) ho·∫°t t·ªët v·ªõi d·ªØ li·ªáu ƒë√∫ng ch√≠nh t·∫£ nh∆∞ng d·ªÖ b·ªè s√≥t c·ª•m nhi·ªÅu token khi c√≥ typo (v√≠ d·ª• `pithon developer`, `ful stack`, `. net ful stack developer`).
- M·ª•c ti√™u: kh·ªõp ·ªü m·ª©c c·ª•m (phrase-level), ch·ªãu l·ªói ch√≠nh t·∫£ nh·∫π, v√† kh√¥ng ph√° v·ª° pipeline hi·ªán t·∫°i.

Nguy√™n l√Ω ch√≠nh c·ªßa `FuzzyPhraseMatcher`:

- So s√°nh span trong vƒÉn b·∫£n v·ªõi full surface form trong surface DB (multi-token only).
- S·ª≠ d·ª•ng ƒë·ªô t∆∞∆°ng ƒë·ªìng Jaro‚ÄìWinkler ƒë·ªÉ ƒë√°nh gi√° m·ª©c gi·ªëng nhau gi·ªØa span v√† surface form.
- Ch·ªâ √°p d·ª•ng cho c√°c entry ƒëa token (multi-token skill / job) ƒë·ªÉ tr√°nh false positive tr√™n single-token.

H√†nh vi khi fuzzy match th√†nh c√¥ng:

- G√°n thu·ªôc t√≠nh `is_matchable = False` cho c√°c token trong span ƒë·ªÉ ngƒÉn c√°c matcher y·∫øu h∆°n (v√≠ d·ª• `low` ho·∫∑c `token`) kh·ªõp l·∫°i v√† ‚ÄúƒÉn m·∫•t‚Äù span ƒë√≥.
- Tr·∫£ v·ªÅ annotation t∆∞∆°ng t·ª± `full_match` (bao g·ªìm `skill_id`, `doc_node_value`, `score`, `doc_node_id`) nh∆∞ng v·ªõi `score` bi·ªÉu th·ªã ƒë·ªô t∆∞∆°ng ƒë·ªìng fuzzy.

L·ª£i √≠ch:

- B·∫Øt ƒë∆∞·ª£c c√°c k·ªπ nƒÉng / job title c√≥ typo ho·∫∑c vi·∫øt kh√¥ng chu·∫©n trong CV/JD.
- Gi·ªØ nguy√™n th·ª© t·ª± matcher hi·ªán t·∫°i v√† tr√°nh xung ƒë·ªôt b·∫±ng c√°ch kho√° span khi fuzzy match th√†nh c√¥ng.

Tri·ªÉn khai g·ª£i √Ω:

- Th√™m `FuzzyPhraseMatcher` nh∆∞ m·ªôt b∆∞·ªõc b·ªï sung trong pipeline matcher, ch·∫°y sau `full` matcher nh∆∞ng tr∆∞·ªõc `low`/`token` matcher.
- C·∫•u h√¨nh ng∆∞·ª°ng Jaro‚ÄìWinkler (v√≠ d·ª• 0.88) l√†m tham s·ªë c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh.
- Ch·ªâ √°p d·ª•ng cho surface forms c√≥ ƒë·ªô d√†i token >= 2.



## üîÑ Pipeline X·ª≠ L√Ω Skills (Phi√™n B·∫£n M·ªõi)

Pipeline m·ªõi ƒë∆∞·ª£c thi·∫øt k·∫ø l·∫°i theo h∆∞·ªõng end-to-end, r√µ r√†ng v√† d·ªÖ b·∫£o tr√¨, cho ph√©p ch·∫°y to√†n b·ªô ho·∫∑c t·ª´ng b∆∞·ªõc ri√™ng l·∫ª, ƒë·ªìng th·ªùi h·ªó tr·ª£ c·∫•u h√¨nh endpoint EMSI linh ho·∫°t.

T·ªïng quan lu·ªìng x·ª≠ l√Ω

EMSI API
     ‚Üì
`raw_skillss.json`
     ‚Üì
`skills_processed.json`
     ‚Üì
`token_dist_skill.json`
     ‚Üì
`skill_db_relax_20.json`

Pipeline n√†y ƒë∆∞·ª£c ƒëi·ªÅu ph·ªëi t·∫≠p trung b·ªüi class `PipelineRunner`.

üß© C·∫•u tr√∫c pipeline & c√°c module ch√≠nh

1Ô∏è‚É£ `pipeline_runner.py` ‚Äì Orchestrator

Vai tr√≤:

 - Ch·∫°y to√†n b·ªô pipeline theo th·ª© t·ª± chu·∫©n: Fetch raw skills t·ª´ Emsi API ‚Üí Process raw ‚Üí T·∫°o token distribution ‚Üí Sinh relax skill DB.

∆Øu ƒëi·ªÉm ch√≠nh:

 - C√≥ th·ªÉ `force_fetch` ho·∫∑c t√°i s·ª≠ d·ª•ng raw c≈©.
 - In log theo t·ª´ng b∆∞·ªõc ƒë·ªÉ d·ªÖ debug.
 - Cho ph√©p c·∫•u h√¨nh: `auth_endpoint`, `skills_endpoint`, ƒë∆∞·ªùng d·∫´n output.

S·ª≠ d·ª•ng:

```python
from pipeline_runner import PipelineRunner

runner = PipelineRunner(
        client_id="YOUR_ID",
        client_secret="YOUR_SECRET"
)

runner.run(force_fetch=False)
```

2Ô∏è‚É£ `fetch_raw_data.py` ‚Äì Fetch d·ªØ li·ªáu t·ª´ Emsi API

`EmsiSkillsFetcher`

Ch·ª©c nƒÉng:

 - L·∫•y access token t·ª´ Emsi.
 - Fetch to√†n b·ªô danh s√°ch skills (Lightcast / EMSI).
 - Cache token ƒë·ªÉ tr√°nh g·ªçi l·∫°i nhi·ªÅu l·∫ßn.
 - L∆∞u raw data ra JSON (`data/raw_skillss.json`).

ƒê·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t:

 - Timeout & error handling r√µ r√†ng.
 - Validate response (ki·ªÉm tra key `data`).
 - Endpoint c√≥ th·ªÉ c·∫•u h√¨nh m√† kh√¥ng s·ª≠a code pipeline.

3Ô∏è‚É£ `processed.py` ‚Äì Chu·∫©n ho√° skill theo chu·∫©n SkillNER

`SkillsProcessor`

Ch·ª©c nƒÉng:

 - L√†m s·∫°ch t√™n skill (Cleaner chu·∫©n SkillNER).
 - Lo·∫°i b·ªè m√¥ t·∫£ trong ngo·∫∑c.
 - Lemmatize (spaCy) v√† stem (PorterStemmer).
 - Tr√≠ch xu·∫•t abbreviation (AWS, SQL, NLP‚Ä¶).

Output: `data/skills_processed.json`

M·ªói skill bao g·ªìm:

```json
{
    "skill_name": "...",
    "skill_type": "...",
    "skill_cleaned": "...",
    "skill_len": 2,
    "skill_lemmed": "...",
    "skill_stemmed": "...",
    "match_on_stemmed": false,
    "abbreviation": "AWS"
}
```

üëâ ƒê·ªãnh d·∫°ng t∆∞∆°ng th√≠ch tr·ª±c ti·∫øp v·ªõi SkillNER g·ªëc.

4Ô∏è‚É£ `create_token_dist.py` ‚Äì Token Distribution

`TokenDistGenerator`

Ch·ª©c nƒÉng:

 - T√≠nh t·∫ßn su·∫•t token.
 - Ch·ªâ d√πng n-gram (skill_len > 1) ƒë·ªÉ tr√°nh nhi·ªÖu.
 - Ph·ª•c v·ª• cho logic relax DB (unique token, rare token).

Output: `data/token_dist_skill.json`

V√≠ d·ª•:

```json
{
    "data": 2134,
    "learning": 1876,
    "cloud": 912
}
```

5Ô∏è‚É£ `create_surf_db.py` ‚Äì Sinh Relax Skill DB

`SkillRelaxDBGenerator`

Ch·ª©c nƒÉng ch√≠nh:

 - Sinh high surface forms: full, abbreviation.
 - Sinh low surface forms: stemmed, ƒë·∫£o token (bigram), token hi·∫øm, abbreviation regex.

Logic theo ƒë·ªô d√†i skill:

 - Skill length 1: match full + stem
 - Skill length 2: full (lemma) + stem + ƒë·∫£o token
 - Skill length >2: full (lemma) + match_on_tokens

Output cu·ªëi c√πng: `data/skill_db_relax_20.json`

üëâ ƒê√¢y l√† file ƒë∆∞·ª£c d√πng tr·ª±c ti·∫øp b·ªüi `SkillExtractor`.

‚ñ∂Ô∏è Ch·∫°y pipeline

Ch·∫°y to√†n b·ªô pipeline:

```python
runner = PipelineRunner()
runner.run()
```

Lu√¥n fetch raw m·ªõi t·ª´ API:

```python
runner.run(force_fetch=True)
```

üì¶ Output sau khi pipeline ho√†n t·∫•t
```
data/
 ‚îú‚îÄ raw_skillss.json
 ‚îú‚îÄ skills_processed.json
 ‚îú‚îÄ token_dist_skill.json
 ‚îî‚îÄ skill_db_relax_20.json
```

B·∫°n c√≥ th·ªÉ d√πng tr·ª±c ti·∫øp `skill_db_relax_20.json` trong:

`SkillExtractor(nlp, SKILL_DB, PhraseMatcher)`

